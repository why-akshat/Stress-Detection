# # -*- coding: utf-8 -*-
# """stress_detection (1).ipynb
#
# Automatically generated by Colaboratory.
#
# Original file is located at
#     https://colab.research.google.com/drive/1-AbQLDP5td-ZgzMvYql6woVDJj8IoymX
# """
# import joblib
# # drive.mount('/content/drive')
# import joblib as jb
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import tensorflow as tf
# from tensorflow import keras
# from keras.models import Sequential
# from keras.layers import Dense, Dropout, LSTM, Flatten
# from keras.layers import Conv1D, MaxPooling1D
# from sklearn.metrics import confusion_matrix
#
#
# X_train = pd.read_csv('data/X_train.csv')
# y_train = pd.read_csv('data/train_split.csv')
# X_val = pd.read_csv('data/X_val.csv')
# y_val = pd.read_csv('data/dev_split.csv')
# X_test = pd.read_csv('data/X_test.csv')
# y_test = pd.read_csv('data/test_split.csv')
#
# y_train = y_train.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)
# y_val = y_val.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)
# y_test = y_test.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)
#
# y_train.rename(columns={'PHQ_Score': 'Label'}, inplace=True)
# y_val.rename(columns={'PHQ_Score': 'Label'}, inplace=True)
# y_test.rename(columns={'PHQ_Score': 'Label'}, inplace=True)
#
# column_to_modify = 'Label'
# mask = y_train[column_to_modify] >= 10
#
# y_train.loc[mask, column_to_modify] = 'stressed'
# y_train.loc[~mask, column_to_modify] = 'distressed'
#
# mask = y_val[column_to_modify] >= 10
#
# y_val.loc[mask, column_to_modify] = 'stressed'
# y_val.loc[~mask, column_to_modify] = 'distressed'
#
# mask = y_test[column_to_modify] >= 10
#
# y_test.loc[mask, column_to_modify] = 'stressed'
# y_test.loc[~mask, column_to_modify] = 'distressed'
#
# print(X_train)
# # print(X_val)
# print(y_train)
# # print(y_val)
#
# xTrainDNN = X_train.values
# xvalDNN = X_val.values
# xTestDNN = X_test.values
# xTrainDNN.shape
#
#
#
# from sklearn.preprocessing import LabelEncoder
# label_encoder = LabelEncoder()
# y_train['Labels'] = label_encoder.fit_transform(y_train['Label'])
# y_val['Labels'] = label_encoder.fit_transform(y_val['Label'])
# y_test['Labels'] = label_encoder.fit_transform(y_test['Label'])
# y_train
#
# yTrainDNN = y_train['Labels']
# yvalDNN = y_val['Labels']
# yTestDNN = y_test['Labels']
# yTrainDNN
#
# yTrainDNN = np.array(yTrainDNN)
# yvalDNN = np.array(yvalDNN)
# yTestDNN = np.array(yTestDNN)
# yTrainDNN
#
# observedEmotions = ['Distressed','Stressed']
#
# # Model configuration
#
# batch_size = 16
# no_epochs = 50
# n_features = 193
# n_testsize = X_val.shape[0]
# n_classes = 2
# validation_split = 0.15
# verbosity = 1
#
#
#
# """### LSTM"""
#
# xTrainLSTM = [x for x in xTrainDNN]
# for i in range(len(xTrainLSTM)):
#     xTrainLSTM[i] = xTrainLSTM[i][:192]
# xTrainLSTM = np.array(xTrainLSTM)
#
#
# xTrainLSTM = np.expand_dims(xTrainLSTM, -1)
# print(xTrainLSTM.shape)
#
# xTestLSTM = [x for x in xTestDNN]
# for i in range(len(xTestLSTM)):
#     xTestLSTM[i] = xTestLSTM[i][:192]
# xTestLSTM = np.array(xTestLSTM)
# xTestLSTM = np.expand_dims(xTestLSTM, -1)
# print(xTestLSTM.shape)
#
# # Create the model
#
# modelLSTM = Sequential([
#     LSTM(128, return_sequences=False, input_shape=(192, 1)),
#     #Dropout(0.2),
#     Dense(64, activation='relu'),
#     #Dropout(0.2),
#     Dense(32, activation='relu'),
#     #Dropout(0.2),
#     Dense(1, activation='sigmoid'),
# ])
#
# modelLSTM.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])
#
# modelLSTM.summary()
#
# # Train the model
#
# historyLSTM = modelLSTM.fit(xTrainLSTM, yTrainDNN, batch_size=16, epochs=no_epochs)
#
# plt_epochs = list(range(50))
# acc = historyLSTM.history['accuracy']
# #val_acc = historyLSTM.history['val_accuracy']
#
# plt.plot(plt_epochs, acc, label='Train accuracy')
# # plt.plot(plt_epochs, val_acc, label='Validation accuracy')
# plt.xlabel('Number of Epochs')
# plt.ylabel('Accuracy')
# plt.legend()
# plt.show()
#
# loss = historyLSTM.history['loss']
# #val_loss = historyLSTM.history['val_loss']
#
# plt.plot(plt_epochs, loss, label='Train loss')
# # plt.plot(plt_epochs, val_loss, label='Validation loss')
# plt.xlabel('Number of Epochs')
# plt.ylabel('Loss')
# plt.legend()
# plt.show()
#
# # ans = [x for x in ans]
# # for i in range(len(ans)):
# #     ans[i] = ans[i][:192]
#
# # print(ans)
# # modelLSTM.predict(ans)
# #
#
# yPredLSTM = modelLSTM.predict(xTestLSTM)
#
# yPredLSTM = (yPredLSTM >= 0.5).astype(int)
# yPredLSTM.shape
#
# import seaborn as sns
# conf_matrix = confusion_matrix(yTestDNN, yPredLSTM)
# conf_matrix
# class_labels = ['Distressed', 'Stressed']
#
# # Create a heatmap of the confusion matrix
# plt.figure(figsize=(8, 6))
# sns.set(font_scale=1.2)  # Adjust font size as needed
# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',
#             xticklabels=class_labels, yticklabels=class_labels)
#
# # Customize labels and appearance
# plt.xlabel('Predicted')
# plt.ylabel('Actual')
# plt.title('Confusion Matrix')
# plt.show()
#
# from sklearn.metrics import accuracy_score
# accuracy = accuracy_score(yTestDNN, yPredLSTM)
# print(accuracy)
#
# joblib.dump(modelLSTM, 'model.sav')
# from sklearn.metrics import accuracy_score
# #accuracy3 = accuracy_score(yTestDNN, yPredDNN)
# #print(accuracy3)
#
# from sklearn.metrics import accuracy_score
# #accuracy4 = accuracy_score(yTestDNN, yPredCNN)
# #print(accuracy4)
# -*- coding: utf-8 -*-
"""stress_detection (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-AbQLDP5td-ZgzMvYql6woVDJj8IoymX
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Flatten
from keras.layers import Conv1D, MaxPooling1D

X_train = pd.read_csv('data/X_train.csv')
y_train = pd.read_csv('data/train_split.csv')
X_val = pd.read_csv('data/X_val.csv')
y_val = pd.read_csv('data/dev_split.csv')
X_test = pd.read_csv('data/X_test.csv')
y_test = pd.read_csv('data/test_split.csv')

y_train = y_train.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)
y_val = y_val.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)
y_test = y_test.drop(['Participant_ID','Gender','PHQ_Binary','PCL-C (PTSD)','PTSD Severity'],axis=1)

y_train.rename(columns={'PHQ_Score': 'Label'}, inplace=True)
y_val.rename(columns={'PHQ_Score': 'Label'}, inplace=True)
y_test.rename(columns={'PHQ_Score': 'Label'}, inplace=True)

column_to_modify = 'Label'
mask = y_train[column_to_modify] >= 10

y_train.loc[mask, column_to_modify] = 'stressed'
y_train.loc[~mask, column_to_modify] = 'distressed'

mask = y_val[column_to_modify] >= 10

y_val.loc[mask, column_to_modify] = 'stressed'
y_val.loc[~mask, column_to_modify] = 'distressed'

mask = y_test[column_to_modify] >= 10

y_test.loc[mask, column_to_modify] = 'stressed'
y_test.loc[~mask, column_to_modify] = 'distressed'

print(X_train)
# print(X_val)
print(y_train)
# print(y_val)

xTrainDNN = X_train.values
xvalDNN = X_val.values
xTestDNN = X_test.values
xTrainDNN.shape
print("fwehfwe")
print(xTestDNN.shape)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y_train['Labels'] = label_encoder.fit_transform(y_train['Label'])
y_val['Labels'] = label_encoder.fit_transform(y_val['Label'])
y_test['Labels'] = label_encoder.fit_transform(y_test['Label'])
y_train

yTrainDNN = y_train['Labels']
yvalDNN = y_val['Labels']
yTestDNN = y_test['Labels']
yTrainDNN

yTrainDNN = np.array(yTrainDNN)
yvalDNN = np.array(yvalDNN)
yTestDNN = np.array(yTestDNN)
yTrainDNN

observedEmotions = ['Distressed','Stressed']

# Model configuration

batch_size = 16
no_epochs = 50
n_features = 193
n_testsize = X_val.shape[0]
n_classes = 2
validation_split = 0.15
verbosity = 1

modelDNN = Sequential([
    Dense(64,activation = 'relu',input_shape=(n_features,)),
#     Dropout(0.2),
    Dense(32,activation='relu'),
#     Dropout(0.2),
    Dense(1,activation = 'sigmoid')
])

modelDNN.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])

modelDNN.summary()

# Train the model
from keras.optimizers.legacy import Adam
# np.random.seed(42)
# tf.random.set_seed(42)
historyDNN = modelDNN.fit(xTrainDNN, yTrainDNN, batch_size=batch_size, epochs=no_epochs, verbose=verbosity)#possible accuracy improve

plt.rcParams["figure.figsize"] = [6, 4]
plt.rcParams["figure.autolayout"] = True

plt_epochs = list(range(50))
acc = historyDNN.history['accuracy']
#val_acc = historyDNN.history['val_accuracy']

plt.plot(plt_epochs, acc, label='Train accuracy')
#plt.plot(plt_epochs, val_acc, label='Validation accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()



loss = historyDNN.history['loss']
#val_loss = historyDNN.history['val_loss']

plt.plot(plt_epochs, loss, label='Train loss')
#plt.plot(plt_epochs, val_loss, label='Validation loss')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

yPredDNN = modelDNN.predict(xTestDNN)
yPredDNN = (yPredDNN >= 0.5).astype(int)
yPredDNN.shape

import seaborn as sns
from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(yTestDNN, yPredDNN)
conf_matrix
class_labels = ['Distressed', 'Stressed']

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size as needed
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',
            xticklabels=class_labels, yticklabels=class_labels)

# Customize labels and appearance
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""### CNN"""

xTrainCNN = [x for x in xTrainDNN]
xTrainCNN = np.array(xTrainCNN)
xTrainCNN.shape

xTrainCNN = np.expand_dims(xTrainCNN, -1)
xTrainCNN.shape

xTestCNN = [x for x in xTestDNN]
xTestCNN = np.array(xTestCNN)
xTestCNN = np.expand_dims(xTestCNN, -1)
xTestCNN.shape

xvalCNN = [x for x in xvalDNN]
xvalCNN = np.array(xvalCNN)
xvalCNN = np.expand_dims(xvalCNN, -1)
xvalCNN.shape

# Create the model

modelCNN = Sequential([
    Conv1D(128, 8, activation='relu', input_shape=(n_features, 1)),
    MaxPooling1D(pool_size=(2)),
    # Dropout(0.2),
    Conv1D(64, 8, activation='relu'),
    MaxPooling1D(pool_size=(2)),
    # Dropout(0.2),
    Flatten(),
    Dense(1, activation='sigmoid'),
])

# Compile the model

modelCNN.compile(loss='binary_crossentropy',
              optimizer='Adam',
              metrics=['accuracy'])

modelCNN.summary()

# Train the model

historyCNN = modelCNN.fit(xTrainCNN, yTrainDNN, batch_size=batch_size, epochs=no_epochs, verbose=verbosity)

plt.rcParams["figure.figsize"] = [6, 4]
plt.rcParams["figure.autolayout"] = True

plt_epochs = list(range(50))
acc = historyCNN.history['accuracy']
#val_acc = historyCNN.history['val_accuracy']

plt.plot(plt_epochs, acc, label='Train accuracy')
# plt.plot(plt_epochs, val_acc, label='Validation accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

loss = historyCNN.history['loss']
#val_loss = historyCNN.history['val_loss']

plt.plot(plt_epochs, loss, label='Train loss')
# plt.plot(plt_epochs, val_loss, label='Validation loss')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

yPredCNN = modelCNN.predict(xTestCNN)
yPredCNN = (yPredCNN >= 0.5).astype(int)
yPredCNN.shape

import seaborn as sns
conf_matrix = confusion_matrix(yTestDNN, yPredCNN)
conf_matrix
class_labels = ['Distressed', 'Stressed']

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size as needed
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',
            xticklabels=class_labels, yticklabels=class_labels)

# Customize labels and appearance
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""### LSTM"""

xTrainLSTM = [x for x in xTrainDNN]
for i in range(len(xTrainLSTM)):
    xTrainLSTM[i] = xTrainLSTM[i][:192]
xTrainLSTM = np.array(xTrainLSTM)
xTrainLSTM.shape

xTrainLSTM = np.expand_dims(xTrainLSTM, -1)
xTrainLSTM.shape

xTestLSTM = [x for x in xTestDNN]
for i in range(len(xTestLSTM)):
    xTestLSTM[i] = xTestLSTM[i][:192]
xTestLSTM = np.array(xTestLSTM)
xTestLSTM = np.expand_dims(xTestLSTM, -1)
xTestLSTM.shape

# Create the model

modelLSTM = Sequential([
    LSTM(128, return_sequences=False, input_shape=(192, 1)),
    #Dropout(0.2),
    Dense(64, activation='relu'),
    #Dropout(0.2),
    Dense(32, activation='relu'),
    #Dropout(0.2),
    Dense(1, activation='sigmoid'),
])

modelLSTM.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])

modelLSTM.summary()

# Train the model

historyLSTM = modelLSTM.fit(xTrainLSTM, yTrainDNN, batch_size=16, epochs=no_epochs)

plt_epochs = list(range(50))
acc = historyLSTM.history['accuracy']
#val_acc = historyLSTM.history['val_accuracy']

plt.plot(plt_epochs, acc, label='Train accuracy')
# plt.plot(plt_epochs, val_acc, label='Validation accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

loss = historyLSTM.history['loss']
#val_loss = historyLSTM.history['val_loss']

plt.plot(plt_epochs, loss, label='Train loss')
# plt.plot(plt_epochs, val_loss, label='Validation loss')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

yPredLSTM = modelLSTM.predict(xTestLSTM)
yPredLSTM = (yPredLSTM >= 0.5).astype(int)
yPredLSTM.shape

import seaborn as sns
conf_matrix = confusion_matrix(yTestDNN, yPredLSTM)
conf_matrix
class_labels = ['Distressed', 'Stressed']

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size as needed
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',
            xticklabels=class_labels, yticklabels=class_labels)

# Customize labels and appearance
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(yTestDNN, yPredLSTM)
#print(accuracy)

from sklearn.metrics import accuracy_score
accuracy3 = accuracy_score(yTestDNN, yPredDNN)
#print(accuracy3)

from sklearn.metrics import accuracy_score
accuracy4 = accuracy_score(yTestDNN, yPredCNN)
#print(accuracy4)
import joblib
# joblib.dump(modelDNN, 'model.sav')

