{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f129c37a-13c7-45e0-88fc-81257a7711cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.58.1-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl (184 kB)\n",
      "     -------------------------------------- 184.6/184.6 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting msgpack>=1.0\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-win_amd64.whl (222 kB)\n",
      "     -------------------------------------- 222.8/222.8 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting joblib>=0.14\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting scikit-learn>=0.20.0\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from librosa) (4.8.0)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from librosa) (1.26.2)\n",
      "Collecting scipy>=1.2.0\n",
      "  Downloading scipy-1.11.3-cp310-cp310-win_amd64.whl (44.1 MB)\n",
      "     ---------------------------------------- 44.1/44.1 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "     ---------------------------------------- 28.1/28.1 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from pooch>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from pooch>=1.0->librosa) (23.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Installing collected packages: threadpoolctl, soxr, scipy, msgpack, llvmlite, lazy-loader, joblib, audioread, scikit-learn, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 joblib-1.3.2 lazy-loader-0.3 librosa-0.10.1 llvmlite-0.41.1 msgpack-1.0.7 numba-0.58.1 pooch-1.8.0 scikit-learn-1.3.2 scipy-1.11.3 soxr-0.3.7 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640b0cc7-97bc-41a9-9335-da5a12aff640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7292c7c1-09a6-4390-a56e-d13a2c9249ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.8 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-gpu==2.8 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: opencv-python in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: matplotlib in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: protobuf==3.19.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (3.10.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (0.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.26.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (3.3.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (2.0.0)\n",
      "Requirement already satisfied: setuptools in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (63.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (23.5.26)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.14.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (0.5.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.59.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (4.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorflow==2.8) (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.41.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.5.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ivp_stressdetection\\stressdetection\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.8 tensorflow-gpu==2.8 opencv-python matplotlib  protobuf==3.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843036e1-9eda-4380-b7cd-60ca48924974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -------------------\n",
      "absl-py                      2.0.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "cachetools                   5.3.2\n",
      "certifi                      2023.7.22\n",
      "charset-normalizer           3.3.2\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.0\n",
      "contourpy                    1.2.0\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.0\n",
      "decorator                    5.1.1\n",
      "exceptiongroup               1.1.3\n",
      "executing                    2.0.1\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.44.3\n",
      "gast                         0.5.4\n",
      "google-auth                  2.23.4\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.59.2\n",
      "h5py                         3.10.0\n",
      "idna                         3.4\n",
      "ipykernel                    6.26.0\n",
      "ipython                      8.17.2\n",
      "jedi                         0.19.1\n",
      "jupyter_client               8.6.0\n",
      "jupyter_core                 5.5.0\n",
      "keras                        2.8.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.5.1\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.8.1\n",
      "matplotlib-inline            0.1.6\n",
      "ml-dtypes                    0.2.0\n",
      "nest-asyncio                 1.5.8\n",
      "numpy                        1.26.2\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.8.1.78\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.2\n",
      "parso                        0.8.3\n",
      "Pillow                       10.1.0\n",
      "pip                          22.2.2\n",
      "platformdirs                 4.0.0\n",
      "prompt-toolkit               3.0.41\n",
      "protobuf                     3.19.1\n",
      "psutil                       5.9.6\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.16.1\n",
      "pyparsing                    3.1.1\n",
      "python-dateutil              2.8.2\n",
      "python-version               0.0.2\n",
      "pywin32                      306\n",
      "pyzmq                        25.1.1\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "setuptools                   63.2.0\n",
      "six                          1.16.0\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.8.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.8.0\n",
      "tensorflow-estimator         2.15.0\n",
      "tensorflow-gpu               2.8.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "tf-estimator-nightly         2.8.0.dev2021122109\n",
      "tornado                      6.3.3\n",
      "traitlets                    5.13.0\n",
      "typing_extensions            4.8.0\n",
      "urllib3                      2.1.0\n",
      "wcwidth                      0.2.10\n",
      "Werkzeug                     3.0.1\n",
      "wheel                        0.41.3\n",
      "wrapt                        1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee4e8ff-ed87-4481-b62d-df6627ae8170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cdfda2e-ef11-4c33-b2e6-c976bb84e15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\IVP_StressDetection\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb717a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23fa988-c210-4f09-b626-ee89eb5ea93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\IVP_StressDetection\\Dataset\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fa742706-9542-425f-8fc8-753a4964490c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def assign_index(filename, column_name):\n",
    "    df = pd.read_csv(filename + '.csv')\n",
    "\n",
    "    # Set a specific column as the index (replace 'column_name' with your column name)\n",
    "    df.set_index(column_name, inplace=True)  # Set the desired column as index\n",
    "\n",
    "    # Convert index values to strings\n",
    "    df.index = df.index.astype(str)\n",
    "\n",
    "    # Extract index values as a list of strings\n",
    "    index_values = df.index.tolist()\n",
    "    \n",
    "    return index_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f29a9e8a-ac25-49c3-a6ea-7b407ca4f99e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def assign_label(filename, column_names):\n",
    "    df = pd.read_csv(filename + '.csv')\n",
    "\n",
    "    index_values = {}\n",
    "    for col in column_names:\n",
    "        try:\n",
    "            # Convert column values to numeric type\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "            # Convert column values to strings based on condition\n",
    "            df[col] = df[col].apply(lambda x: '1' if x >= 10 else '0')\n",
    "            # Set each specified column as the index\n",
    "            df.set_index(col, inplace=True)\n",
    "            # Store index values in a dictionary\n",
    "            index_values = df.index.tolist()\n",
    "            # Reset the index after processing each column\n",
    "        except ValueError:\n",
    "            print(f\"Error processing column '{col}'. Ensure the values are numeric.\")\n",
    "\n",
    "    return index_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dcb15194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['600', '602', '604', '605', '606', '607', '615', '618', '619', '624', '626', '631', '636', '638', '650', '651', '652', '655', '656', '658', '663', '664', '676', '679', '682', '688', '693', '696', '699', '705', '708', '710', '712', '715', '716', '718']\n",
      "153\n",
      "36\n",
      "153\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "file_names_train = assign_index(\"train_split\", \"Participant_ID\") \n",
    "file_names_test = assign_index(\"test_split\", \"Participant_ID\")\n",
    "file_names_val = assign_index(\"dev_split\", \"Participant_ID\")\n",
    "\n",
    "column_to_process = ['PHQ_Score']\n",
    "\n",
    "labels_train = assign_label(\"train_split\", column_to_process)\n",
    "labels_test = assign_label(\"test_split\", column_to_process)\n",
    "labels_val = assign_label(\"dev_split\", column_to_process)\n",
    "print(file_names_test)\n",
    "\n",
    "print(len(file_names_train))\n",
    "print(len(file_names_test))\n",
    "print(len(labels_train))\n",
    "print(len(labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7ec128b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create lists for file paths and label names\n",
    "def openfile(file_names,labels):\n",
    "    file_paths = []\n",
    "    label_names = []\n",
    "\n",
    "    for dire, label in zip(file_names,labels):\n",
    "        # Create the full file path\n",
    "        file_path = f\"{dire}_P/{dire}_P/{dire}_AUDIO.wav\"\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "        # Convert label to distress or stress\n",
    "        label_name = \"distressed\" if label == \"0\" else \"stressed\"\n",
    "        label_names.append(label_name)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data_df = pd.DataFrame({'Path': file_paths, 'Label': label_names})\n",
    "\n",
    "    # Display the DataFrame\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "120ca0c9-ac7f-4d54-af71-9bde55b2a423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = openfile(file_names_train,labels_train)\n",
    "test_data = openfile(file_names_test,labels_test)\n",
    "val_data = openfile(file_names_val,labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b776d649-2e3c-4cbd-86ab-674c8ec608c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Path       Label\n",
      "0   600_P/600_P/600_AUDIO.wav  distressed\n",
      "1   602_P/602_P/602_AUDIO.wav    stressed\n",
      "2   604_P/604_P/604_AUDIO.wav    stressed\n",
      "3   605_P/605_P/605_AUDIO.wav  distressed\n",
      "4   606_P/606_P/606_AUDIO.wav  distressed\n",
      "5   607_P/607_P/607_AUDIO.wav  distressed\n",
      "6   615_P/615_P/615_AUDIO.wav  distressed\n",
      "7   618_P/618_P/618_AUDIO.wav  distressed\n",
      "8   619_P/619_P/619_AUDIO.wav  distressed\n",
      "9   624_P/624_P/624_AUDIO.wav    stressed\n",
      "10  626_P/626_P/626_AUDIO.wav  distressed\n",
      "11  631_P/631_P/631_AUDIO.wav  distressed\n",
      "12  636_P/636_P/636_AUDIO.wav    stressed\n",
      "13  638_P/638_P/638_AUDIO.wav    stressed\n",
      "14  650_P/650_P/650_AUDIO.wav  distressed\n",
      "15  651_P/651_P/651_AUDIO.wav  distressed\n",
      "16  652_P/652_P/652_AUDIO.wav  distressed\n",
      "17  655_P/655_P/655_AUDIO.wav    stressed\n",
      "18  656_P/656_P/656_AUDIO.wav  distressed\n",
      "19  658_P/658_P/658_AUDIO.wav    stressed\n",
      "20  663_P/663_P/663_AUDIO.wav  distressed\n",
      "21  664_P/664_P/664_AUDIO.wav  distressed\n",
      "22  676_P/676_P/676_AUDIO.wav  distressed\n",
      "23  679_P/679_P/679_AUDIO.wav  distressed\n",
      "24  682_P/682_P/682_AUDIO.wav    stressed\n",
      "25  688_P/688_P/688_AUDIO.wav    stressed\n",
      "26  693_P/693_P/693_AUDIO.wav  distressed\n",
      "27  696_P/696_P/696_AUDIO.wav    stressed\n",
      "28  699_P/699_P/699_AUDIO.wav    stressed\n",
      "29  705_P/705_P/705_AUDIO.wav    stressed\n",
      "30  708_P/708_P/708_AUDIO.wav  distressed\n",
      "31  710_P/710_P/710_AUDIO.wav  distressed\n",
      "32  712_P/712_P/712_AUDIO.wav  distressed\n",
      "33  715_P/715_P/715_AUDIO.wav  distressed\n",
      "34  716_P/716_P/716_AUDIO.wav    stressed\n",
      "35  718_P/718_P/718_AUDIO.wav  distressed\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "018ff56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "distressed    107\n",
       "stressed       46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e124f934-d515-41f2-a152-ece2b66c7493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trimm(data):\n",
    "    data_trimmed, _ = librosa.effects.trim(data, top_db=20)\n",
    "    return data_trimmed\n",
    "\n",
    "def pitch(data, samplingRate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=samplingRate, n_steps=pitch_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8b9aab0d-6294-4dec-9ed2-7e7a1a8a336d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature extraction (mfcc, delta, double-delta, chroma)\n",
    "\n",
    "def extract_features(filename):\n",
    "    with sf.SoundFile(filename) as soundFile:\n",
    "        x = soundFile.read(dtype=\"float64\")\n",
    "        sampleRate = soundFile.samplerate\n",
    "        res = np.array([])\n",
    "        \n",
    "        x = trimm(x)\n",
    "        x = pitch(x, sampleRate, 3)\n",
    "        \n",
    "        stft = np.abs(librosa.stft(x))\n",
    "        \n",
    "        # for mfcc\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=x, sr=sampleRate, n_mfcc=13).T, axis=0)\n",
    "        res = np.hstack((res, mfccs))\n",
    "        \n",
    "        # for delta\n",
    "        delta_mfcc = librosa.feature.delta(mfccs)\n",
    "        res = np.hstack((res, delta_mfcc))\n",
    "        \n",
    "        # for double-delta\n",
    "        delta2_mfcc = librosa.feature.delta(mfccs, order=2)\n",
    "        res = np.hstack((res, delta2_mfcc))\n",
    "        \n",
    "        # for chroma\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampleRate).T, axis=0)\n",
    "        res = np.hstack((res, chroma))\n",
    "        \n",
    "        # for mel spectrogram\n",
    "        melSpec = np.mean(librosa.feature.melspectrogram(y=x, sr=sampleRate).T, axis=0)\n",
    "        res = np.hstack((res, melSpec))\n",
    "        \n",
    "        # for contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sampleRate).T, axis=0)\n",
    "        res = np.hstack((res, contrast))\n",
    "        \n",
    "        # for tonnetz\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=x, sr=sampleRate).T, axis=0)\n",
    "        res = np.hstack((res, tonnetz))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "21f2628e-f394-4a99-9ae5-0ef32b2810b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def loadData(df,test_size=0.15):\n",
    "    x= []\n",
    "    for ind in df.index:\n",
    "        emotion = df['Label'][ind]\n",
    "        file = df['Path'][ind] \n",
    "        a = file[:3]\n",
    "        b=int(a)\n",
    "        \n",
    "        #f(b>631):\n",
    "        print(file)\n",
    "        feature = extract_features(file)\n",
    "        x.append(feature)\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cd1bf-f283-46ae-b770-667c48e0e08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "i=0\n",
    "\n",
    "# Path to the tar file\n",
    "#for name in file_names_train:\n",
    "    if(i<=15):\n",
    "        i=i+1\n",
    "        continue\n",
    "    else:\n",
    "        tar_file_path = name+\"_P.tar\"\n",
    "\n",
    "        # Open the tar file\n",
    "        with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
    "            # Extract all contents to a specific directory\n",
    "            tar_ref.extractall(name+\"_P\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10dd1105-4320-4a08-b254-1f0015799ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c18f7135-2cb5-4498-a651-729a26d7e4af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "26175cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600_P/600_P/600_AUDIO.wav\n",
      "602_P/602_P/602_AUDIO.wav\n",
      "604_P/604_P/604_AUDIO.wav\n",
      "605_P/605_P/605_AUDIO.wav\n",
      "606_P/606_P/606_AUDIO.wav\n",
      "607_P/607_P/607_AUDIO.wav\n",
      "615_P/615_P/615_AUDIO.wav\n",
      "618_P/618_P/618_AUDIO.wav\n",
      "619_P/619_P/619_AUDIO.wav\n",
      "624_P/624_P/624_AUDIO.wav\n",
      "626_P/626_P/626_AUDIO.wav\n",
      "631_P/631_P/631_AUDIO.wav\n",
      "636_P/636_P/636_AUDIO.wav\n",
      "638_P/638_P/638_AUDIO.wav\n",
      "650_P/650_P/650_AUDIO.wav\n",
      "651_P/651_P/651_AUDIO.wav\n",
      "652_P/652_P/652_AUDIO.wav\n",
      "655_P/655_P/655_AUDIO.wav\n",
      "656_P/656_P/656_AUDIO.wav\n",
      "658_P/658_P/658_AUDIO.wav\n",
      "663_P/663_P/663_AUDIO.wav\n",
      "664_P/664_P/664_AUDIO.wav\n",
      "676_P/676_P/676_AUDIO.wav\n",
      "679_P/679_P/679_AUDIO.wav\n",
      "682_P/682_P/682_AUDIO.wav\n",
      "688_P/688_P/688_AUDIO.wav\n",
      "693_P/693_P/693_AUDIO.wav\n",
      "696_P/696_P/696_AUDIO.wav\n",
      "699_P/699_P/699_AUDIO.wav\n",
      "705_P/705_P/705_AUDIO.wav\n",
      "708_P/708_P/708_AUDIO.wav\n",
      "710_P/710_P/710_AUDIO.wav\n",
      "712_P/712_P/712_AUDIO.wav\n",
      "715_P/715_P/715_AUDIO.wav\n",
      "716_P/716_P/716_AUDIO.wav\n",
      "718_P/718_P/718_AUDIO.wav\n"
     ]
    }
   ],
   "source": [
    "# X_train,X_test,y_train,y_test = loadData(data_df)\n",
    "\n",
    "#X_train = loadData(train_data)\n",
    "X_test = loadData(test_data)\n",
    "#X_val = loadData(val_data)\n",
    "#X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aaaa0e9f-a3ec-482f-a7a5-f884f8844421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_train\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d9e6413d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_train_df = pd.DataFrame(X_train,columns = [f\"feat_{i}\" for i in range(192)])\n",
    "X_test_df = pd.DataFrame(X_test,columns = [f\"feat_{i}\" for i in range(192)])\n",
    "#X_val_df = pd.DataFrame(X_val,columns = [f\"feat_{i}\" for i in range(192)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a6dc7e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_train_df.to_csv('X_train.csv')\n",
    "X_test_df.to_csv('X_test.csv')\n",
    "#X_val_df.to_csv('X_val.csv')\n",
    "# y_train_df.to_csv('y_train_imbalanced.csv')\n",
    "# y_test_df.to_csv('y_test_imbalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163743d-00b6-41ae-bbdc-3eaf974b7c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73042623-ef7d-4d1f-aeb1-16ecdffbbe34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae52db-63f4-45d4-9137-704b32442818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d1558-ee5a-4a26-8ba4-1f876e3d3171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec6c3d-0dab-444f-bd9e-c763d3b1f1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109fee9-e707-4950-b713-1970eace0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StressDetection",
   "language": "python",
   "name": "stressdetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
